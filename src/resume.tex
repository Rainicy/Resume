\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{amssymb}
\textheight=10in
\pagestyle{empty}
%\raggedbottom
\raggedright

%  \renewcommand{\encodingdefault}{cg}
  %\renewcommand{\rmdefault}{lgrcmr}

%\def\bull{\vrule height 0.8ex width .7ex depth -.1ex }
% DEFINITIONS FOR RESUME
%\newcommand{\area}[2]{\vspace*{-9pt} \begin{verse}\textbf{#1}   #2 \end{verse}  }
\newcommand{\area}[2]{\hspace*{-1pt} \begin{verse}\textbf{#1}   #2 \end{verse}  }
\newcommand{\lineunder}{\vspace*{-8pt} \\ \hspace*{-18pt} \hrulefill \\}
\newcommand{\header}[1]{{\hspace*{-15pt}\vspace*{6pt} \large \textsc{\textbf{#1}}} \vspace*{-6pt} \lineunder}
\newcommand{\employer}[3]{{ \textbf{#1} (#2)\\ \underline{\textbf{\emph{#3}}}\\  }}
\newcommand{\contact}[4]{
\vspace*{-8pt}
\begin{center}
{\LARGE \scshape {#1}}\\
#2\\
#3 \\%\lineunder 
#4
\end{center}
\vspace*{-8pt}
}
\newenvironment{achievements}{\begin{list}{$\bullet$}{\topsep 0pt \itemsep -2pt}}{\vspace*{4pt}\end{list}}
\newcommand{\schoolwithcourses}[4]{
 \textbf{#1} #2 $\bullet$ #3\\ 
#4 $\bullet$  Selected Coursework:\\
\vspace*{5pt}
}
\newcommand{\school}[4]{
 \textbf{#1} #2 $\bullet$ #3\\ 
#4 \\
}
\newcommand{\headerrow}[2]
{\begin{tabular*}{\linewidth}{l@{\extracolsep{\fill}}r}
	\hspace*{-15pt}#1 & #2 \\
\end{tabular*}}
%% \newcommand{\headerroww}[3]
%% {\begin{tabular*}{\linewidth}{l@{\extracolsep{\fill}}r}
%% 	#1 &
%% 	#2 \\
%% 	#3 \\
%% \end{tabular*}}
\newcommand{\headerrowwf}[2]
{\begin{tabular*}{\linewidth}{l@{\extracolsep{\fill}}r}
	\hspace*{-15pt}#1 & #2 \\
\end{tabular*}}
\newcommand{\headerrowww}[1]
{\begin{tabular*}{\linewidth}{l@{\extracolsep{\fill}}r}
	#1 &\\
\end{tabular*}}
\newcommand{\res}[1]{{\hspace*{-15pt}\vspace*{6pt} \textsc{#1}} \vspace*{-6pt} \lineunder}
% END RESUME DEFINITIONS

%%% 
%%% % indentsection style, used for sections that aren't already in lists
%%% % that need indentation to the level of all text in the document
%%% \newenvironment{indentsection}[1]%
%%% {\begin{list}{}%
%%% 	{\setlength{\leftmargin}{#1}}%
%%% 	\item[]%
%%% }
%%% {\end{list}}
%%% 
%%% % opposite of above; bump a section back toward the left margin
%%% \newenvironment{unindentsection}[1]%
%%% {\begin{list}{}%
%%% 	{\setlength{\leftmargin}{-0.5#1}}%
%%% 	\item[]%
%%% }
%%% {\end{list}}
%%% 
% format two pieces of text, one left aligned and one right aligned
%%%% \newcommand{\headerrow}[2]
%%%% {\begin{tabular*}{\linewidth}{l@{\extracolsep{\fill}}r}
%%%% 	#1 &
%%%% 	#2 \\
%%%% \end{tabular*}}
%%%% 
%%%% % make "C++" look pretty when used in text by touching up the plus signs
\newcommand{\CPP}
 {C\nolinebreak[4]\hspace{-.05em}\raisebox{.22ex}{\footnotesize\bf ++}}

\begin{document}

\small
\smallskip
\vspace*{-35pt}

\contact{Bingyu Wang}
{(617) 750-6151 $\bullet$ rainicy@ccs.neu.edu}
{69 Park Dr, Apt 6, Boston, MA, 02215}

\header{Education}
\headerrow
{\textbf{Northeastern University} \emph{Candidate for PhD of Computer Science, GPA: 3.85/4.00}}
{\emph{2015-present}}

% \headerrowwf
% {\emph{Candidate for PhD of Computer Science, GPA: 3.85/4.00}}
% {\emph{Jan.2015 - present}}

\headerrowwf
{---\textbf{Core Courses}:
Algorithms $\cdot$ Machine Learning  $\cdot$ Data Mining $\cdot$ Information Theory }
{\emph{}}

\hspace*{-8pt}\textbf{---Teaching Assistant}:
Machine Learning $\cdot$ Information Retrieval \\
% \hspace*{107pt} 20th ACM SIGKDD Conference (New York City, \emph{Aug 2014})
% \hspace*{107pt} Big Data Technology Conference (Boston, \emph{April 2014})
\vspace*{1.5pt}

\headerrow
{\textbf{Northeastern University} \emph{Master of Computer Science, GPA: 3.85/4.00}}
{\emph{Sep 2012-Dec 2014}}
% {\text{Xi'an, China}}
\\
% \headerrowwf
% {\emph{Bachelor of Engineering in Software Engineering, GPA: 3.30/4.00}}
% {\emph{June 2012}}

% \headerrowwf
% {\textbf{Core Courses}:
% Object Oriental Technique \& \CPP, Java Program Designing  $\cdot$ Algorithm Data Structure \\
% \hspace*{54pt}$\cdot$  Web Design and Technology  $\cdot$  Database System $\cdot$ Linear Algebra $\cdot$ Probability Theory}
% {\emph{}}
% \hspace*{-8pt}\textbf{Honors and Activities}: University First Scholarship 
% \& Excellent Student Award (\emph{2010 - 2011})
% \hspace*{104pt}$\cdot$ 1st Prize in Professional Computer Knowledge Competition (\emph{2010}).

% \vspace*{2.5pt}
% \header{Publications}
% \headerrow
% {\text{``Topic-Factorized Ideal Point Estimation Model for Legislative Voting Network"}}
% {\emph{ACM SIGKDD 2014}}


\vspace*{1.5pt}
\header{Research Experience}

\headerrow
{\textbf{Big Data in Relationship between Air Pollution and Mortality Risk}\emph{(Ongoing)}}
{\emph{2016-present}}
% \headerrowww
% {\emph{Ongoing Project}}
\begin{achievements}
	\item Developed models such as Cox and Poisson Regression, to handle over 45 billion observations.
	\item Conducted big data study to identify patterns and trends in air pollution associated-mortality risk
\end{achievements}

\headerrow
{\textbf{Extreme Multi-Label Classification(XCBM)}\emph{(Ongoing)}}
{\emph{2017-present}}
% \headerrowww
% {\emph{Ongoing Project}}
\begin{achievements}
	\item Developed a sparse CBM(XCBM) by exploring feature sparsity, label sparsity and label imbalance. 
	\item Derived and implemented a Weighted Dual Coordinate Descent method to speed up training.
	\item XCBM achieved a comparable performance comparing with other extreme classifiers.
\end{achievements}

\headerrow
{\textbf{Regularizing Model and Label Structure for Multi-Label Classification}\emph{(Ongoing)}}
{\emph{2016-2017}}
% \headerrowww
% {\emph{Ongoing Project}}
\begin{achievements}
	\item Regularized Multi-Label classifiers by ElasticNet to avoid overfitting and shrink model size.
	\item Combined General F-Measure Maximizer(GFM) with Support Inferences to obtain optimal instance-F1 prediction.
	\item Achieved better instance-F1 comparing with existing Multi-Label methods. 
\end{achievements}

\headerrow
{\textbf{Conditional Bernoulli Mixtures(CBM) for Multi-label Classification}}
{\emph{2015-2016}}
\begin{achievements}
	\item Derived and implemented a new Multi-label classifier using Mixtures of Bernoulli.
	\item Developed an efficient inference to make joint prediction by dynamic programming.
	\item CBM outperformed other state-of-the-art Multi-Label methods.
\end{achievements}

\headerrow
{\textbf{Topic-Factorized Ideal Point Estimation Model for Legislative Voting Network}}
{\emph{2013-2014}}
\begin{achievements}
	\item Crawled Roll Call Votes data and built the dictionaries for Bill Text, Voting records and legislators.
	\item Implemented the topic models on bill texts, like Probabilistic latent semantic analysis (PLSA),  latent Dirichlet allocation (LDA) for the baseline.
	\item Visualized the voters' ideological positions on website, using D3js. 
\end{achievements}



\vspace*{1.5pt}
\header{Professional Experience}

\headerrow
{\textbf{MassMutual Financial Group, Boston, MA}}
{\emph{Jan-June 2014}}
\\
\headerrowww
{\emph{Data Analyst (Python)}}
	\begin{achievements}
	\item Recognized the pattern and performed analysis and predictions on the web log data of Oppenheimer Website using the Aster Express Tool from Teradata
	\item Analyzed the MassMutual HR data and produced the predictions on the Quality of Hire
	\item Performed twitter analysis for GeoAnalytics project to collect data from twitter using sentimental keywords and find out the areas where MassMutual can promote the sales
	\end{achievements}
	

\headerrow
{\textbf{Federal Home Loan Bank, Boston, MA}}
{\emph{June-Aug 2013}}
\\
\headerrowww
{\emph{Information Technology Intern (Java)}}
	\begin{achievements}
	\item Developed a Test Automation Framework that can easily be used to test different web based projects 
	using various technologies, such as Selenium, Open2Test and Eclipse
	\item Delivered  documentations, including test script based on SharePoint, test results covering 
	test suite execution and screenshot, and user manual for non-computer staff 
	\end{achievements}
	
% \headerrow
% {\textbf{Software Engineering Laboratory, Northwestern Univ., Xi'an, China}}
% {\emph{Feb-Nov 2011}}
% \\
% \headerrowww
% {\emph{Student Data Analyst (MATLAB)}}
% 	\begin{achievements}
% 	\item Designed models of data warehouse, including concept, logic and physics models
% 	\item Eliminated redundant and obsolete data through applications of various algorithms
% 	\item Built prediction models from vast data source using data mining techniques
% 	\end{achievements}
	



% \headerrow
% {\textbf{Solving The Issue of Mazes: Shortest Path Based-on Genetic Algorithm, Capstone}}
% {\emph{2011-2012}}
% 	\begin{achievements}
%   \item Coded the front-end GUI for generating and configuring mazes using MFC in \CPP
%   \item Studied and developed a new genetic algorithms (sub-optimal) to search for shortest path under various population size, length of gene,  mutation rate and crossover rate
%   \item Evaluated and assessed performance and attribute of the algorithm on various platforms
%   \end{achievements}

% \headerrow
% {\textbf{Research on Web Page Ranking: Based on Learning to Rank Algorithms}}
% {\emph{2013}}
% 	\begin{achievements}
%   \item Implemented the RankBoost and Gradient Boosting Decision Tree Algorithms to perform the web page ranking task
%   \item Improved the accuracy by building decision tree in heap structure and increased the running speed by simplifying the squared error formula and sorting the features
%   \item Reduced the running time from several hours to almost half an hour on 1GB datasets
%   \end{achievements}
  
\vspace*{1.5pt}
\header{Publications}
\headerrow
{\textit{Gu, Chen, Sun, \textbf{Wang}.} ``Ideology Detection for Twitter Users via Link Analysis''}
{\emph{SBP-BRiMS 2017}}

\headerrow
{\textit{Li, \textbf{Wang}, Pavlu, Aslam.} ``Conditional Bernoulli Mixtures for Multi-Label Classification''}
{\emph{ICML 2016}}

\headerrow
{\textit{Li, \textbf{Wang}, Pavlu, Aslam.} ``An Empirical Study of Skip-gram Features and Regularization for \\Learning on Sentiment Analysis''}
{\emph{ECIR 2016}}

\headerrow
{\textit{Gu, Sun, Jiang, \textbf{Wang}, Chen.} ``Topic-Factorized Ideal Point Estimation Model for Legislative \\ Voting Network''}
{\emph{KDD 2014}}


\vspace*{1.5pt}
\header{Computer Knowledge}
Java, Python, MATLAB, LaTex, D3js
% \begin{achievements}
% \item Programming Languages (Proficiency): Java, Python, MATLAB
% \item Programming Languages (Familiar):  C, \CPP,  LaTex
% \item Operating Systems and Databases: UNIX-Like (Mac OS X, GNU/Linux), SQL Server 2000, SQLite
% \item Web and Mobile Development: D3.js, Android Development
% \end{achievements}


\end{document}
